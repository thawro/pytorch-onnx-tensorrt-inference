# PyTorch - ONNX - TensorRT inference comparison
Inference time comparison between PyTorch, ONNX and TensorRT engines

# Compare
Run
```bash
python run_measurements.py
```
to compare the inference times of default model (resnet152 loaded from torchvision)